# Day 4: Introduction to Automation and Nextflow

## Overview

### Lead Instructor
- [Phelelani Mpangase](https://github.com/phelelani) |  [@???](https://twitter.com/???) | [email](mailto:Phelelani.Mpangase@wits.ac.za)

### Co-Instructor(s)
- [Scott Hazelhurst](http://dept.ee.wits.ac.za/~scott/) | [@???](https://twitter.com/???) | [email](mailto:scott.Hazelhurst@wits.ac.za)

### Helper(s)
- Maria Tsagiopoulou | [@tsayo7](https://twitter.com/tsayo7) [email](mariatsayo@gmail.com)


### General Topics

- Introduction to Nextflow
  - Use of workflow systems for automation / reproducibility
  - Basic syntax of Nextflow
  - Transform and execute a workflow in Nextflow


## Schedule

- _**09:00 - 10:00**_ Introduction to Nextflow

- _**10:00 - 11:00**_ Parameters, Channels and Processes

- _**11:00 - 11:30**_ _**Coffee break**_

- _**11:30 - 12:30**_ Docker, Executors and Channel Operations

- _**12:30 - 14:00**_ _**Lunch break**_

- _**14:00 - 15:00**_ Practical exercises in Nextflow

- _**15:00 - 16:00**_ Practical exercises in Nextflow

- _**16:00 - 16:15**_ _**Coffee break**_

- _**16:15 - 18:00**_ Practical exercises in Nextflow


## Learning Objectives

- Find and use Nextflow tool definitions online
- Understand how to write Nextflow definitions for command line tools
- Use Docker with Nextflow to provide software dependencies and ensure reproducibility
- Join Nextflow tools into a workflow
- Run Nextflow workflows on local and HPC systems


## Introduction to Automation and Nextflow

The **slides** of the talk are available [**here**]().

<H3 align="center"> Reproducible workflows using Nextflow </H3>
<p align="center">
  <img width="1000" src="_static/images/best_practices.png">
  Flow chart summarizing the resources and best practices for development, maintenance, sharing and publishing of reproducible and portable workflows.
</p>

### Our first Nexflow script
First, lets set up a directory where we will do all our Nextflow exercises:
```
mkdir $HOME/day4
cd $HOME/day4
```

Then, we download the data we will be using for the exercises:
```
wget http://www.bioinf.wits.ac.za/adme-workshop/Friday/tutorial.zip
unzip tutorial.zip
```
Tyep `ls -l` and hit <ENTER> to view the contents of the directory.

**Exercise 1:** You have an input file with 6 columns (see below), where column 2 is an "index" column. Identify rows that have **identical** indexes (column 2) and remove them from the file. Your input file looks like this:
```
11   11:189256   0   189256   A   G
11   11:193788   0   193788   T   C
11   11:194062   0   194062   T   C
11   11:194228   0   194228   A   G
11   11:193788   0   193788   A   C
```
Let's download our input file and have a look at it:
```
wget <>
less -S 11.bim
mv 11.bim data/
```

**Solution - using `bash`:**
```
cut -f 2 11.bim | sort | uniq -d > dups
grep -f dups 11.bim > 11.clean
```
This is easy to do in `bash` - very simple example, not realistic for Nextflow

**Solution - using `Nextflow`:**
```groovy
#!/usr/bin/env nexflow

input_ch = Channel.fromPath("data/11.bim")

process getIDs {
    input:
    file input from input_ch

    output:
    file "ids" into id_ch
    file "11.bim" into orig_ch
  
    script:
    "cut -f 2 $input | sort > ids"
}

process getDups {
    input:
    file input from id_ch
  
    output:
    file "dups" into dups_ch
  
    script:
    """
    uniq -d $input > dups
    touch ignore
    """
}

process removeDups {
    input:
    file badids from dups_ch
    file orig from orig_ch
    
    output:
    file "clean.bim" into output
    
    script:
    "grep -v -f $badids $orig > clean.bim "
}

output.subscribe { print "Done!" }
```
Using a text editor like `emacs` or `vim`, create a file named `cleandups.nf` and copy the contents of the `nextflow` script above into `cleandups.nf` file.

Note, the use of `nextflow` variables: Within a double quoted string, there is string interpolation marked with the `$`. If you want to access a system environment variable you need to also escape with a backslash. So in the Nextflow program, you can normally just refer to Nextflow variables unadorned with their names (e.g. `$input`) and environment variables with a  dollar (e.g. `$HOME`) but within a double/triple-quoted string it's `\$input` and `\$HOME`. File names can be relative (to the current working directory where the script is being run in, not to the location of the script), or absolute. Great care needs to be taken with using absolute path names since this reduces the portability of scripts, particualarly when you are using Docker. 

Now we can execute our script:
```
nextflow run cleandups.nf
```
The output we get:
```
N E X T F L O W  ~  version 19.07.0
Launching `cleandups.nf` [distraught_lamarr] - revision: fb99ce6125
executor >  local (3)
[b3/aa0380] process > getIDs (1)     [100%] 1 of 1 ✔
[90/cebf36] process > getDups (1)    [100%] 1 of 1 ✔
[9c/e0cb7d] process > removeDups (1) [100%] 1 of 1 ✔
Done!
```
Note that `nextflow` creates a `work` directory, and inside of that are the working directories of each process -- in the example above you can see that the `getIDs` process was launched in a directory with a prefix `aa0380`, inside the directory `b3`. The directory structure is looks like:
```
day4
|--cleandups.nf
|--data
|--work
|  |--90
|  |  |--cebf3649d883f88381e32b4912b560
|  |  |  |--ids -> /Users/phele/day4/work/b3/aa0380f2a1bca447259b7ffd390083/ids
|  |  |  |--ignore
|  |--9c
|  |  |--e0cb7d8d26682d7d4a1c44392f2bb3
|  |  |  |--11.bim -> /Users/phele/day4/data/11.bim
|  |  |  |--clean.bim
|  |  |  |--dups -> /Users/phele/day4/work/90/cebf3649d883f88381e32b4912b560/dups
|  |--b3
|  |  |--aa0380f2a1bca447259b7ffd390083
|  |  |  |--11.bim -> /Users/phele/day4/data/11.bim
|  |  |  |--ids
```
The names of the working directory are randomly chosen so if you run it, you will get different names. Also, each time you run a process ever, it will get a unique working directory. There is  no danger of name clashes Instead of naming the file you get from a channel you can also:
- specify `stdin` if your process expects data to come from `stdin` rather than a named file. Nextflow will pipe the file to standard input;
- specify `stdout` if your process produces data on `stdout` and you want that data to go into the `channel`

**Exercise:** Change the script so that you use `stdin` or `stdout` in the `getIDs` and `getDups` processes to avoid the use of the temporary file `ids`. You can see the solution [here](files/data/cleandups.nf)


#### Partial Execution
```
nextflow run cleandups.nf -resume
```

####  Visualising the workflow
```
--with-dag
--with-timeline
--with-report
```

**DAG**:`nextflow run cleandups.nf --with-dag <file-name>.dot`
<p align="center">
  <img width="1000" src="_static/images/dag.png">
</p>


**DAG**:`nextflow run cleandups.nf --with-timeline <file-name>.html`
<p align="center">
  <img width="1000" src="_static/images/timeline.png">
</p>


**DAG**:`nextflow run cleandups.nf --with-report <file-name>.html`
<p align="center">
  <img width="1000" src="_static/images/report.png">
</p>


#### Exercise Material:
- [x] GitHub repository:
```
git clone http://github.com/shaze/nextflow-course
```
- [x] Exercise data:
```
wget http://www.bioinf.wits.ac.za/adme-workshop/Friday/tutorial.zip
```
